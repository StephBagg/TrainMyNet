{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6884,
     "status": "ok",
     "timestamp": 1527238503018,
     "user": {
      "displayName": "Richard D",
      "photoUrl": "//lh4.googleusercontent.com/-vRpYLfbjfFg/AAAAAAAAAAI/AAAAAAAAAkQ/-qIAB7MuIqs/s50-c-k-no/photo.jpg",
      "userId": "117572936419671535970"
     },
     "user_tz": -120
    },
    "id": "uz87d1Wt-eUD",
    "outputId": "474df4d0-7cc5-4099-ce1d-155c3aa21a67"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1527238505814,
     "user": {
      "displayName": "Richard D",
      "photoUrl": "//lh4.googleusercontent.com/-vRpYLfbjfFg/AAAAAAAAAAI/AAAAAAAAAkQ/-qIAB7MuIqs/s50-c-k-no/photo.jpg",
      "userId": "117572936419671535970"
     },
     "user_tz": -120
    },
    "id": "RB4-KyBt_BNu",
    "outputId": "805926b9-4671-45bd-f780-94dd5eeac552"
   },
   "outputs": [],
   "source": [
    "random_img = np.random.randint(len(train_data))\n",
    "print(train_data.shape)\n",
    "print(max(train_data[random_img]))\n",
    "print(min(train_data[random_img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1527238547389,
     "user": {
      "displayName": "Richard D",
      "photoUrl": "//lh4.googleusercontent.com/-vRpYLfbjfFg/AAAAAAAAAAI/AAAAAAAAAkQ/-qIAB7MuIqs/s50-c-k-no/photo.jpg",
      "userId": "117572936419671535970"
     },
     "user_tz": -120
    },
    "id": "1tr4HS-b_R0R",
    "outputId": "35ca865a-747e-450c-f6d6-86c2589b5de2"
   },
   "outputs": [],
   "source": [
    "#scale data to range [-1,1] --> as we use tanh activation in the output of the generated images. \n",
    "train_images =  train_data*2 - 1\n",
    "print(max(train_images[random_img]))\n",
    "print(min(train_images[random_img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bW5kHsAoBLEe"
   },
   "outputs": [],
   "source": [
    "kernel_size = [5,5]\n",
    "stride = [2,2]\n",
    "\n",
    "def gen(input_tensor, reuse=False):#input tensor is z: [-1, 100]\n",
    "    with tf.variable_scope('generator'):\n",
    "        act_fun_g = tf.nn.relu\n",
    "\n",
    "        fully = tf.layers.dense(input_tensor, \n",
    "                                7*7*64,\n",
    "                                activation=act_fun_g,\n",
    "                                reuse=reuse,\n",
    "                                name='g_hid1')\n",
    "        fully_r = tf.reshape(fully, shape=[-1,7,7,64])\n",
    "\n",
    "        cnn_T_layer1 = tf.layers.conv2d_transpose(fully_r, 32, kernel_size, strides=stride,\n",
    "                                                  padding='same',\n",
    "                                                  activation=act_fun_g,\n",
    "                                                  reuse=reuse,\n",
    "                                                  name='g_CNN_T1')#image is now double the size --> 14x14\n",
    "        \n",
    "        cnn_T_layer2 = tf.layers.conv2d_transpose(cnn_T_layer1, 1, kernel_size, strides=stride,\n",
    "                                                  padding='same',\n",
    "                                                  activation=None,\n",
    "                                                  reuse=reuse,\n",
    "                                                  name='g_CNN_T2')#image is now double the size --> 28x28\n",
    "\n",
    "        output = tf.reshape(cnn_T_layer2,[-1, 784])\n",
    "        return tf.nn.tanh(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gVYq5As9I6dC"
   },
   "outputs": [],
   "source": [
    "def dis(input_tensor, reuse=False):#input_tensor is an image [-1, 784]\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        act_fun_d = tf.nn.leaky_relu#default leak: alpha = 0.2\n",
    "\n",
    "        input_tensor_r = tf.reshape(input_tensor, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        cnn_layer1 = tf.layers.conv2d(input_tensor_r, 32, kernel_size, strides=stride,\n",
    "                                      padding='same',\n",
    "                                      activation=act_fun_d,\n",
    "                                      reuse=reuse,\n",
    "                                      name='d_CNN1')#image is now half the size --> 14x14\n",
    "\n",
    "        cnn_layer2 = tf.layers.conv2d(cnn_layer1, 64, kernel_size, strides=stride,\n",
    "                                      padding='same',\n",
    "                                      activation=act_fun_d,\n",
    "                                      reuse=reuse,\n",
    "                                      name='d_CNN2')#image is now half the size --> 7x7\n",
    "        cnn_layer2_r = tf.reshape(cnn_layer2,[-1, 7*7*64])\n",
    "\n",
    "        output = tf.layers.dense(cnn_layer2_r, \n",
    "                                 1,\n",
    "                                 activation=None,\n",
    "                                 reuse=reuse,\n",
    "                                 name='d_out')\n",
    "\n",
    "        return tf.nn.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZBXglvv9KFqN"
   },
   "outputs": [],
   "source": [
    "def gen_train(d_fake, LR):\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        global_step = tf.get_variable('global_step',dtype=tf.int32)\n",
    "  \n",
    "    g_loss = tf.reduce_mean(-tf.log(d_fake))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=LR,beta1=0.5)\n",
    "    g_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "    g_train = optimizer.minimize(g_loss, var_list=g_var, global_step=global_step)\n",
    "    return g_train, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i8zuCQlAMaxA"
   },
   "outputs": [],
   "source": [
    "def dis_train(d_fake, d_real, LR):\n",
    "    d_loss = -0.5*tf.reduce_mean((tf.log(d_real) + tf.log(1.0 - d_fake)))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=LR,beta1=0.5)\n",
    "    d_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "    d_train = optimizer.minimize(d_loss, var_list=d_var)\n",
    "    return d_train, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v5xUvisQPA3d"
   },
   "outputs": [],
   "source": [
    "def random_batch(x, batch_size):\n",
    "    loc = np.random.randint(len(x), size=batch_size)\n",
    "    return x[loc,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5AASevC2NQYJ"
   },
   "outputs": [],
   "source": [
    "#run time!\n",
    "z_dim = 100\n",
    "LR = 0.0002\n",
    "x_dim = 784\n",
    "batch_size = 128\n",
    "\n",
    "def training():\n",
    "    with tf.Graph().as_default():\n",
    "        sess = tf.Session()\n",
    "        global_step = tf.get_variable('global_step', shape=[],dtype=tf.int32)\n",
    "        \n",
    "        x = tf.placeholder(tf.float32, [batch_size, x_dim], 'real-images')\n",
    "        \n",
    "        z = tf.random_normal([batch_size, z_dim], mean=0, stddev=1.0)#Latent: Gaussian\n",
    "        \n",
    "        gen_x = gen(z, reuse=False)\n",
    "        \n",
    "        d_fake = dis(gen_x, reuse=False)\n",
    "        d_real = dis(x, reuse=True)\n",
    "        \n",
    "        g_train, g_loss = gen_train(d_fake, LR)\n",
    "        d_train, d_loss = dis_train(d_fake, d_real, LR)\n",
    "       \n",
    "        initial_var = tf.global_variables_initializer()\n",
    "        sess.run(initial_var)\n",
    "        \n",
    "        train = True\n",
    "        step = 0\n",
    "        \n",
    "        while train == True:\n",
    "            real_data = random_batch(train_images, batch_size)\n",
    "            _g, _d = sess.run([g_train, d_train], feed_dict={x: real_data})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                loss_g, loss_d, gen_images = sess.run([g_loss, d_loss, gen_x], feed_dict={x: real_data})\n",
    "                print()\n",
    "                print('------------------------------------------------------------------------------')\n",
    "                print('At step:', step)\n",
    "                print('G loss =', loss_g)\n",
    "                print('D loss =', loss_d)\n",
    "                plt.subplot(1, 4, 1)\n",
    "                plt.title('real')\n",
    "                plt.imshow(np.reshape(real_data[0], [28,28]), cmap='gray')\n",
    "                \n",
    "                plt.subplot(1, 4, 2)\n",
    "                plt.title('generated')\n",
    "                plt.imshow(np.reshape(gen_images[0], [28,28]), cmap='gray')\n",
    "                \n",
    "                plt.subplot(1, 4, 3)\n",
    "                plt.title('real')\n",
    "                plt.imshow(np.reshape(real_data[1], [28,28]), cmap='gray')\n",
    "                \n",
    "                plt.subplot(1, 4, 4)\n",
    "                plt.title('generated')\n",
    "                plt.imshow(np.reshape(gen_images[1], [28,28]), cmap='gray')\n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "                \n",
    "            step += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 46368
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 392644,
     "status": "error",
     "timestamp": 1527238949157,
     "user": {
      "displayName": "Richard D",
      "photoUrl": "//lh4.googleusercontent.com/-vRpYLfbjfFg/AAAAAAAAAAI/AAAAAAAAAkQ/-qIAB7MuIqs/s50-c-k-no/photo.jpg",
      "userId": "117572936419671535970"
     },
     "user_tz": -120
    },
    "id": "IaRNmqsmQAF9",
    "outputId": "29c15d4e-eee5-40be-8571-0ed49c0e8b38"
   },
   "outputs": [],
   "source": [
    "training() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yzhnxkWOQCB7"
   },
   "outputs": [],
   "source": [
    "#run time!\n",
    "z_dim = 100\n",
    "LR = 0.0002\n",
    "x_dim = 784\n",
    "batch_size = 128\n",
    "noise_var = 1.5\n",
    "noise_steps = 5000\n",
    "\n",
    "def training():\n",
    "    with tf.Graph().as_default():\n",
    "        sess = tf.Session()\n",
    "        global_step = tf.get_variable('global_step', shape=[],dtype=tf.int32)\n",
    "        \n",
    "        noise = tf.train.polynomial_decay(noise_var, global_step,noise_steps,0.0,power=1.0)#linear decay to zero noise by step: noise_steps\n",
    "        \n",
    "        x = tf.placeholder(tf.float32, [batch_size, x_dim], 'real-images')\n",
    "        \n",
    "        z = tf.random_normal([batch_size, z_dim], mean=0, stddev=1.0)#Latent: Gaussian\n",
    "        \n",
    "        gen_x = gen(z, reuse=False)\n",
    "        \n",
    "        gen_x_n = gen_x + tf.random_normal([batch_size, x_dim], mean=0.0, stddev=noise)#adding noise\n",
    "        x_n = x + tf.random_normal([batch_size, x_dim], mean=0.0, stddev=noise)\n",
    "        \n",
    "        d_fake = dis(gen_x_n, reuse=False)\n",
    "        d_real = dis(x_n, reuse=True)\n",
    "        \n",
    "        g_train, g_loss = gen_train(d_fake, LR)\n",
    "        d_train, d_loss = dis_train(d_fake, d_real, LR)\n",
    "       \n",
    "        initial_var = tf.global_variables_initializer()\n",
    "        sess.run(initial_var)\n",
    "        \n",
    "        train = True\n",
    "        step = 0\n",
    "        \n",
    "        while train == True:\n",
    "            real_data = random_batch(train_images, batch_size)\n",
    "            _g, _d = sess.run([g_train, d_train], feed_dict={x: real_data})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                loss_g, loss_d, gen_images, var_noise, gen_images_n, real_data_n = sess.run([g_loss, d_loss, gen_x, noise, gen_x_n, x_n], feed_dict={x: real_data})\n",
    "                print()\n",
    "                print('------------------------------------------------------------------------------')\n",
    "                print('At step:', step, ', with variance of noise =', var_noise)\n",
    "                print('G loss =', loss_g)\n",
    "                print('D loss =', loss_d)\n",
    "                print()\n",
    "                print('Without Noise')\n",
    "                plt.subplot(1, 4, 1)\n",
    "                plt.title('real')\n",
    "                plt.imshow(np.reshape(real_data[0], [28,28]), cmap='gray')\n",
    "                \n",
    "                plt.subplot(1, 4, 2)\n",
    "                plt.title('generated')\n",
    "                plt.imshow(np.reshape(gen_images[0], [28,28]), cmap='gray')\n",
    "                \n",
    "                plt.subplot(1, 4, 3)\n",
    "                plt.title('real')\n",
    "                plt.imshow(np.reshape(real_data[1], [28,28]), cmap='gray')\n",
    "                \n",
    "                plt.subplot(1, 4, 4)\n",
    "                plt.title('generated')\n",
    "                plt.imshow(np.reshape(gen_images[1], [28,28]), cmap='gray')\n",
    "                plt.show()\n",
    "                \n",
    "                if step <= noise_steps:\n",
    "                    print()\n",
    "                    print('With Noise')\n",
    "                    plt.subplot(1, 4, 1)\n",
    "                    plt.title('real')\n",
    "                    plt.imshow(np.reshape(real_data_n[0], [28,28]), cmap='gray')\n",
    "\n",
    "                    plt.subplot(1, 4, 2)\n",
    "                    plt.title('generated')\n",
    "                    plt.imshow(np.reshape(gen_images_n[0], [28,28]), cmap='gray')\n",
    "\n",
    "                    plt.subplot(1, 4, 3)\n",
    "                    plt.title('real')\n",
    "                    plt.imshow(np.reshape(real_data_n[1], [28,28]), cmap='gray')\n",
    "\n",
    "                    plt.subplot(1, 4, 4)\n",
    "                    plt.title('generated')\n",
    "                    plt.imshow(np.reshape(gen_images_n[1], [28,28]), cmap='gray')\n",
    "                    plt.show()                \n",
    "                \n",
    "            step += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 33512
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 180910,
     "status": "error",
     "timestamp": 1527237544850,
     "user": {
      "displayName": "Richard D",
      "photoUrl": "//lh4.googleusercontent.com/-vRpYLfbjfFg/AAAAAAAAAAI/AAAAAAAAAkQ/-qIAB7MuIqs/s50-c-k-no/photo.jpg",
      "userId": "117572936419671535970"
     },
     "user_tz": -120
    },
    "id": "laExCYGJZeD_",
    "outputId": "dfa1bbb9-e05d-4f0f-ff7b-444e7344dfe4"
   },
   "outputs": [],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-zh55DWlZfup"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "dcgan_mnist.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
